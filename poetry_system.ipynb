{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16aa9d7c",
   "metadata": {},
   "source": [
    "### STATE DEFINITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3ade133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from typing import Dict\n",
    "from typing import Annotated\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd1ab546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20cac8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoemState(TypedDict):\n",
    "    \"\"\"State that flows through the LangGraph workflow\"\"\"\n",
    "    document_path: str\n",
    "    document_text: str\n",
    "    factual_context: Dict\n",
    "    verses: Annotated[List[Dict], operator.add]\n",
    "    current_verse_num: int\n",
    "    max_verses: int\n",
    "    poet_turn: str  # \"poet_a\" or \"poet_b\"\n",
    "    judgments: List[Dict]\n",
    "    winner: str\n",
    "    error: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6498ded7",
   "metadata": {},
   "source": [
    "### Document processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51eec53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# import pytesseract\n",
    "import PyPDF2\n",
    "from docx import Document as DocxDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f2cfdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_image(image_path: str) -> str:\n",
    "    \"\"\"Extract text from image using OCR\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        text = pytesseract.image_to_string(img)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "975dafbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"Extract text from PDF\"\"\"\n",
    "    try:\n",
    "        text = []\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            for page in pdf_reader.pages:\n",
    "                text.append(page.extract_text())\n",
    "        return \"\\n\".join(text)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c098b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_docx(docx_path: str) -> str:\n",
    "    \"\"\"Extract text from DOCX\"\"\"\n",
    "    try:\n",
    "        doc = DocxDocument(docx_path)\n",
    "        text = [para.text for para in doc.paragraphs]\n",
    "        return \"\\n\".join(text)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "075879f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_txt(txt_path: str) -> str:\n",
    "    \"\"\"Read text file\"\"\"\n",
    "    try:\n",
    "        with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8d9bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(file_path: str) -> str:\n",
    "    \"\"\"Route document to appropriate processor\"\"\"\n",
    "    path = Path(file_path)\n",
    "    ext = path.suffix.lower()\n",
    "    \n",
    "    processors = {\n",
    "        '.jpg': extract_text_from_image,\n",
    "        '.jpeg': extract_text_from_image,\n",
    "        '.png': extract_text_from_image,\n",
    "        '.pdf': extract_text_from_pdf,\n",
    "        '.docx': extract_text_from_docx,\n",
    "        '.doc': extract_text_from_docx,\n",
    "        '.txt': extract_text_from_txt\n",
    "    }\n",
    "    \n",
    "    processor = processors.get(ext)\n",
    "    if processor:\n",
    "        return processor(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {ext}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ad2547",
   "metadata": {},
   "source": [
    "### CHAINS FOR EACH TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b3dd92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c156e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fact_extraction_chain(llm):\n",
    "    \"\"\"Create LangChain for extracting structured facts\"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a fact extraction expert. Extract structured information from text.\n",
    "        Return ONLY a valid JSON object with these exact keys:\n",
    "        - entities: list of people, places, organizations, concepts\n",
    "        - key_facts: list of concrete factual statements\n",
    "        - themes: list of main themes or topics\n",
    "        - temporal_info: list of dates, time periods, sequences\n",
    "        - numerical_data: list of numbers, statistics, measurements\n",
    "\n",
    "        Be precise and extract actual facts from the text.\"\"\"),\n",
    "        (\"human\", \"Extract facts from this text:\\n\\n{text}\\n\\nReturn JSON only:\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    \n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c3f932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_poet_chain(llm, poet_name: str, style: str):\n",
    "    \"\"\"Create LangChain for a specific poet\"\"\"\n",
    "    \n",
    "    personas = {\n",
    "        \"metaphorical\": \"\"\"You are a poet who transforms facts into vivid metaphors and imagery.\n",
    "        You MUST reference specific facts but express them through symbolism, nature imagery, and sensory details.\n",
    "        You maintain strict factual accuracy while elevating language to art.\"\"\",\n",
    "        \n",
    "        \"narrative\": \"\"\"You are a poet who tells clear stories with concrete details.\n",
    "        You MUST reference specific facts directly - names, dates, numbers, events.\n",
    "        You craft verses with clarity, accessibility, and emotional resonance.\"\"\"\n",
    "    }\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", personas[style]),\n",
    "        (\"human\", \"\"\"CRITICAL INSTRUCTIONS:\n",
    "        1. You MUST reference at least ONE specific fact from the context below\n",
    "        2. Use actual names, dates, numbers, or events from the context\n",
    "        3. Do NOT make up information\n",
    "        4. Continue naturally from previous verses\n",
    "\n",
    "        FACTUAL CONTEXT (USE THESE FACTS):\n",
    "        {context}\n",
    "\n",
    "        POEM SO FAR:\n",
    "        {previous_verses}\n",
    "\n",
    "        Now write verse #{verse_num} in {style} style.\n",
    "\n",
    "        Format your response EXACTLY like this:\n",
    "        LINE: [your verse here - 1-2 lines, max 20 words]\n",
    "        FACTS_USED: [comma-separated list of specific facts you referenced]\n",
    "\n",
    "        Example:\n",
    "        LINE: Armstrong stepped on lunar soil, July 20, marking history forever.\n",
    "        FACTS_USED: Neil Armstrong, July 20 1969, moon landing\"\"\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    \n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c724236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_judging_chain(llm):\n",
    "    \"\"\"Create LangChain for judging poetry\"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are an expert poetry critic. Evaluate contributions fairly and provide specific feedback.\"\"\"),\n",
    "        (\"human\", \"\"\"Evaluate {poet_name}'s verses in this collaborative poem.\n",
    "\n",
    "        FACTUAL SOURCE MATERIAL:\n",
    "        {context}\n",
    "\n",
    "        FULL POEM:\n",
    "        {full_poem}\n",
    "\n",
    "        {poet_name}'s VERSES ONLY:\n",
    "        {poet_verses}\n",
    "\n",
    "        Rate each criterion 0-10:\n",
    "        1. FACTUAL_ACCURACY: How well grounded in source material? Do verses reference actual facts?\n",
    "        2. POETIC_QUALITY: Aesthetic merit, imagery, rhythm, word choice\n",
    "        3. COHERENCE: Flow with overall poem and previous verses\n",
    "        4. CREATIVITY: Originality, fresh perspectives, unexpected connections\n",
    "        5. EMOTIONAL_IMPACT: Evocative power, ability to engage reader\n",
    "\n",
    "        Respond EXACTLY in this format:\n",
    "\n",
    "        SCORES:\n",
    "        factual_accuracy: [number 0-10]\n",
    "        poetic_quality: [number 0-10]\n",
    "        coherence: [number 0-10]\n",
    "        creativity: [number 0-10]\n",
    "        emotional_impact: [number 0-10]\n",
    "\n",
    "        STRENGTHS:\n",
    "        - [specific strength with example]\n",
    "        - [specific strength with example]\n",
    "        - [specific strength with example]\n",
    "\n",
    "        WEAKNESSES:\n",
    "        - [specific weakness with example]\n",
    "        - [specific weakness with example]\n",
    "\n",
    "        STANDOUT_VERSES: [comma-separated line numbers, e.g. 1,3,7]\n",
    "\n",
    "        REASONING:\n",
    "        [2-3 paragraphs explaining your scores with specific examples from their verses]\"\"\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    \n",
    "    return chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db6336f",
   "metadata": {},
   "source": [
    "### LANGGRAPH NODE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0bc71222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6bd1843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document_node(state: PoemState) -> Dict:\n",
    "    \"\"\"Node: Load and process document\"\"\"\n",
    "    try:\n",
    "        text = process_document(state['document_path'])\n",
    "        return {\"document_text\": text}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Document processing failed: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "622a2948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b00f4d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "438a3b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_facts_node(state: PoemState) -> Dict:\n",
    "    \"\"\"Node: Extract factual context using LangChain\"\"\"\n",
    "    \n",
    "    llm = ChatGroq(\n",
    "        model=\"openai/gpt-oss-120b\",\n",
    "        temperature=0.1,\n",
    "        groq_api_key=os.getenv('GROQ_API_KEY')\n",
    "    )\n",
    "    \n",
    "    chain = create_fact_extraction_chain(llm)\n",
    "    \n",
    "    try:\n",
    "        result = chain.invoke({\"text\": state['document_text']})\n",
    "        \n",
    "        # Parse JSON from response\n",
    "        result = result.strip()\n",
    "        if result.startswith('```json'):\n",
    "            result = result.split('```json')[1].split('```')[0].strip()\n",
    "        elif result.startswith('```'):\n",
    "            result = result.split('```')[1].split('```')[0].strip()\n",
    "        \n",
    "        facts = json.loads(result)\n",
    "        \n",
    "        print(f\"   Entities: {len(facts.get('entities', []))}\")\n",
    "        print(f\"   Key Facts: {len(facts.get('key_facts', []))}\")\n",
    "        print(f\"   Themes: {len(facts.get('themes', []))}\")\n",
    "        \n",
    "        return {\"factual_context\": facts}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   Fact extraction error: {e}\")\n",
    "        # Fallback: create basic context\n",
    "        return {\"factual_context\": {\n",
    "            \"entities\": [\"subject from document\"],\n",
    "            \"key_facts\": [\"main event or information\"],\n",
    "            \"themes\": [\"primary theme\"],\n",
    "            \"temporal_info\": [\"timeframe if mentioned\"],\n",
    "            \"numerical_data\": [\"statistics if present\"]\n",
    "        }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d658671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_verse_node(state: PoemState) -> Dict:\n",
    "    \"\"\"Node: Generate next verse\"\"\"\n",
    "    verse_num = state['current_verse_num']\n",
    "    poet_turn = state['poet_turn']\n",
    "    \n",
    "    # Determine poet details\n",
    "    if poet_turn == \"poet_a\":\n",
    "        poet_name = \"Poet A (Metaphorical)\"\n",
    "        style = \"metaphorical\"\n",
    "    else:\n",
    "        poet_name = \"Poet B (Narrative)\"\n",
    "        style = \"narrative\"\n",
    "    \n",
    "    print(f\"  Verse {verse_num}: {poet_name}\")\n",
    "    \n",
    "    llm = ChatGroq(\n",
    "        model=\"openai/gpt-oss-120b\",\n",
    "        temperature=0.7,\n",
    "        groq_api_key=os.getenv('GROQ_API_KEY')\n",
    "    )\n",
    "    \n",
    "    chain = create_poet_chain(llm, poet_name, style)\n",
    "    \n",
    "    # Format previous verses\n",
    "    if state['verses']:\n",
    "        previous_verses = \"\\n\".join([\n",
    "            f\"{v['line_number']}. [{v['author']}] {v['line']}\"\n",
    "            for v in state['verses']\n",
    "        ])\n",
    "    else:\n",
    "        previous_verses = \"[This is the first verse of the poem]\"\n",
    "    \n",
    "    # Format context - CRITICAL FIX\n",
    "    fc = state['factual_context']\n",
    "    context_parts = []\n",
    "    \n",
    "    if fc.get('entities'):\n",
    "        context_parts.append(f\"ENTITIES: {', '.join(fc['entities'][:8])}\")\n",
    "    if fc.get('key_facts'):\n",
    "        context_parts.append(f\"KEY FACTS: {' | '.join(fc['key_facts'][:5])}\")\n",
    "    if fc.get('themes'):\n",
    "        context_parts.append(f\"THEMES: {', '.join(fc['themes'][:4])}\")\n",
    "    if fc.get('temporal_info'):\n",
    "        context_parts.append(f\"DATES/TIME: {', '.join(fc['temporal_info'][:4])}\")\n",
    "    if fc.get('numerical_data'):\n",
    "        context_parts.append(f\"NUMBERS: {', '.join(map(str, fc['numerical_data'][:4]))}\")\n",
    "        # context_parts.append(f\"NUMBERS: {', '.join(fc['numerical_data'][:4])}\")\n",
    "    \n",
    "    context = \"\\n\".join(context_parts) if context_parts else \"No specific facts extracted\"\n",
    "    \n",
    "    try:\n",
    "        result = chain.invoke({\n",
    "            \"context\": context,\n",
    "            \"previous_verses\": previous_verses,\n",
    "            \"verse_num\": verse_num,\n",
    "            \"style\": style\n",
    "        })\n",
    "        \n",
    "        # Parse result\n",
    "        lines = result.strip().split('\\n')\n",
    "        verse_line = \"\"\n",
    "        facts_used = []\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith('LINE:'):\n",
    "                verse_line = line.replace('LINE:', '').strip()\n",
    "            elif line.startswith('FACTS_USED:'):\n",
    "                facts_str = line.replace('FACTS_USED:', '').strip()\n",
    "                facts_used = [f.strip() for f in facts_str.split(',') if f.strip()]\n",
    "        \n",
    "        # Fallback if parsing fails\n",
    "        if not verse_line:\n",
    "            verse_line = result.strip().split('\\n')[0].replace('LINE:', '').strip()\n",
    "        \n",
    "        verse = {\n",
    "            \"line\": verse_line,\n",
    "            \"author\": poet_name,\n",
    "            \"line_number\": verse_num,\n",
    "            \"factual_anchors\": facts_used\n",
    "        }\n",
    "        \n",
    "        print(f\"   \\\"{verse_line[:60]}...\\\"\")\n",
    "        \n",
    "        # Update state\n",
    "        next_turn = \"poet_b\" if poet_turn == \"poet_a\" else \"poet_a\"\n",
    "        \n",
    "        return {\n",
    "            \"verses\": [verse],\n",
    "            \"current_verse_num\": verse_num + 1,\n",
    "            \"poet_turn\": next_turn\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   Error: {e}\")\n",
    "        # Return placeholder verse\n",
    "        verse = {\n",
    "            \"line\": f\"[Verse {verse_num} generation failed]\",\n",
    "            \"author\": poet_name,\n",
    "            \"line_number\": verse_num,\n",
    "            \"factual_anchors\": []\n",
    "        }\n",
    "        next_turn = \"poet_b\" if poet_turn == \"poet_a\" else \"poet_a\"\n",
    "        return {\n",
    "            \"verses\": [verse],\n",
    "            \"current_verse_num\": verse_num + 1,\n",
    "            \"poet_turn\": next_turn\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c1b1f0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_completion_node(state: PoemState) -> str:\n",
    "    \"\"\"Node: Check if poem is complete\"\"\"\n",
    "    if state['current_verse_num'] > state['max_verses']:\n",
    "        return \"judge\"\n",
    "    else:\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "23527159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_poems_node(state: PoemState) -> Dict:\n",
    "    \"\"\"Node: Judge both poets' contributions\"\"\"\n",
    "    print(\"Judging contributions...\")\n",
    "    \n",
    "    llm = ChatGroq(\n",
    "        model=\"openai/gpt-oss-120b\",\n",
    "        temperature=0.3,\n",
    "        groq_api_key=os.getenv('GROQ_API_KEY')\n",
    "    )\n",
    "    \n",
    "    chain = create_judging_chain(llm)\n",
    "    \n",
    "    # Separate verses by author\n",
    "    poet_verses = {}\n",
    "    for verse in state['verses']:\n",
    "        author = verse['author']\n",
    "        if author not in poet_verses:\n",
    "            poet_verses[author] = []\n",
    "        poet_verses[author].append(verse)\n",
    "    \n",
    "    # Format full poem\n",
    "    full_poem = \"\\n\".join([\n",
    "        f\"{v['line_number']}. [{v['author']}] {v['line']}\"\n",
    "        for v in state['verses']\n",
    "    ])\n",
    "    \n",
    "    # Format context\n",
    "    fc = state['factual_context']\n",
    "    context = f\"\"\"Entities: {', '.join(fc.get('entities', [])[:8])}\n",
    "Key Facts: {'; '.join(fc.get('key_facts', [])[:5])}\n",
    "Themes: {', '.join(fc.get('themes', [])[:4])}\n",
    "Dates: {', '.join(fc.get('temporal_info', [])[:4])}\n",
    "Numbers: {', '.join(map(str, fc.get('numerical_data', [])[:4]))}\n",
    "\"\"\"\n",
    "    \n",
    "    judgments = []\n",
    "    \n",
    "    for poet_name, verses in poet_verses.items():\n",
    "        poet_lines = \"\\n\".join([\n",
    "            f\"{v['line_number']}. {v['line']}\"\n",
    "            for v in verses\n",
    "        ])\n",
    "        \n",
    "        try:\n",
    "            print(f\"   Evaluating {poet_name}...\")\n",
    "            result = chain.invoke({\n",
    "                \"poet_name\": poet_name,\n",
    "                \"context\": context,\n",
    "                \"full_poem\": full_poem,\n",
    "                \"poet_verses\": poet_lines\n",
    "            })\n",
    "            \n",
    "            # Parse judgment\n",
    "            judgment = parse_judgment(result, poet_name)\n",
    "            judgments.append(judgment)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error judging {poet_name}: {e}\")\n",
    "            # Fallback judgment\n",
    "            judgments.append({\n",
    "                'poet_name': poet_name,\n",
    "                'criteria': {\n",
    "                    'factual_accuracy': 5.0,\n",
    "                    'poetic_quality': 5.0,\n",
    "                    'coherence': 5.0,\n",
    "                    'creativity': 5.0,\n",
    "                    'emotional_impact': 5.0\n",
    "                },\n",
    "                'strengths': [\"Unable to evaluate - see error\"],\n",
    "                'weaknesses': [\"Evaluation failed\"],\n",
    "                'standout_verses': [],\n",
    "                'reasoning': f\"Error during judgment: {str(e)}\"\n",
    "            })\n",
    "    \n",
    "    # Determine winner\n",
    "    if len(judgments) == 2:\n",
    "        score1 = calculate_overall_score(judgments[0]['criteria'])\n",
    "        score2 = calculate_overall_score(judgments[1]['criteria'])\n",
    "        winner = judgments[0]['poet_name'] if score1 > score2 else judgments[1]['poet_name']\n",
    "    else:\n",
    "        winner = \"Unknown\"\n",
    "    \n",
    "    return {\n",
    "        \"judgments\": judgments,\n",
    "        \"winner\": winner\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cc3411",
   "metadata": {},
   "source": [
    "### HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "408eb46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_judgment(response: str, poet_name: str) -> Dict:\n",
    "    \"\"\"Parse judgment response into structured data\"\"\"\n",
    "    lines = response.split('\\n')\n",
    "    \n",
    "    scores = {}\n",
    "    strengths = []\n",
    "    weaknesses = []\n",
    "    standout_verses = []\n",
    "    reasoning = []\n",
    "    \n",
    "    current_section = None\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        \n",
    "        if line.startswith('SCORES:'):\n",
    "            current_section = 'scores'\n",
    "        elif line.startswith('STRENGTHS:'):\n",
    "            current_section = 'strengths'\n",
    "        elif line.startswith('WEAKNESSES:'):\n",
    "            current_section = 'weaknesses'\n",
    "        elif line.startswith('STANDOUT_VERSES:'):\n",
    "            current_section = 'standout'\n",
    "            verses_str = line.replace('STANDOUT_VERSES:', '').strip()\n",
    "            try:\n",
    "                standout_verses = [int(v.strip()) for v in verses_str.split(',') if v.strip().isdigit()]\n",
    "            except:\n",
    "                pass\n",
    "        elif line.startswith('REASONING:'):\n",
    "            current_section = 'reasoning'\n",
    "        elif current_section == 'scores' and ':' in line:\n",
    "            key, value = line.split(':', 1)\n",
    "            try:\n",
    "                scores[key.strip()] = float(value.strip())\n",
    "            except ValueError:\n",
    "                pass\n",
    "        elif current_section == 'strengths' and line.startswith('-'):\n",
    "            strengths.append(line[1:].strip())\n",
    "        elif current_section == 'weaknesses' and line.startswith('-'):\n",
    "            weaknesses.append(line[1:].strip())\n",
    "        elif current_section == 'reasoning' and not line.startswith('-'):\n",
    "            reasoning.append(line)\n",
    "    \n",
    "    return {\n",
    "        'poet_name': poet_name,\n",
    "        'criteria': {\n",
    "            'factual_accuracy': scores.get('factual_accuracy', 5.0),\n",
    "            'poetic_quality': scores.get('poetic_quality', 5.0),\n",
    "            'coherence': scores.get('coherence', 5.0),\n",
    "            'creativity': scores.get('creativity', 5.0),\n",
    "            'emotional_impact': scores.get('emotional_impact', 5.0)\n",
    "        },\n",
    "        'strengths': strengths if strengths else [\"Evaluation completed\"],\n",
    "        'weaknesses': weaknesses if weaknesses else [\"See detailed feedback\"],\n",
    "        'standout_verses': standout_verses,\n",
    "        'reasoning': '\\n'.join(reasoning) if reasoning else \"Detailed analysis provided above.\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5d556ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_score(criteria: Dict) -> float:\n",
    "    \"\"\"Calculate weighted overall score\"\"\"\n",
    "    weights = {\n",
    "        'factual_accuracy': 0.25,\n",
    "        'poetic_quality': 0.25,\n",
    "        'coherence': 0.20,\n",
    "        'creativity': 0.15,\n",
    "        'emotional_impact': 0.15\n",
    "    }\n",
    "    \n",
    "    return sum(criteria[k] * weights[k] for k in weights.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb709573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(results: Dict):\n",
    "    \"\"\"Pretty print results\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COLLABORATIVE POEM\".center(80))\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    for verse in results['verses']:\n",
    "        print(f\"{verse['line_number']}. [{verse['author']}]\")\n",
    "        print(f\"   {verse['line']}\")\n",
    "        if verse.get('factual_anchors'):\n",
    "            print(f\"   Facts: {', '.join(verse['factual_anchors'][:3])}\")\n",
    "        print()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"JUDGMENTS\".center(80))\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    for judgment in results['judgments']:\n",
    "        overall = calculate_overall_score(judgment['criteria'])\n",
    "        \n",
    "        print(f\"\\n{judgment['poet_name']}\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Overall Score: {overall:.2f}/10\")\n",
    "        print(f\"\\nDetailed Scores:\")\n",
    "        for criterion, score in judgment['criteria'].items():\n",
    "            print(f\"  {criterion.replace('_', ' ').title()}: {score}/10\")\n",
    "        \n",
    "        print(f\"\\nStrengths:\")\n",
    "        for strength in judgment['strengths']:\n",
    "            print(f\"  {strength}\")\n",
    "        \n",
    "        print(f\"\\nWeaknesses:\")\n",
    "        for weakness in judgment['weaknesses']:\n",
    "            print(f\"  {weakness}\")\n",
    "        \n",
    "        if judgment['standout_verses']:\n",
    "            print(f\"\\nStandout Verses: {', '.join(map(str, judgment['standout_verses']))}\")\n",
    "        \n",
    "        if judgment['reasoning']:\n",
    "            print(f\"\\nReasoning:\\n{judgment['reasoning'][:300]}...\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"WINNER: {results['winner']}\")\n",
    "    print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a2bf08",
   "metadata": {},
   "source": [
    "### LANGGRAPH WORKFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59ff2072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph imports\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09812551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_poetry_workflow():\n",
    "    \"\"\"Create LangGraph workflow for collaborative poetry\"\"\"\n",
    "    \n",
    "    workflow = StateGraph(PoemState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"load_document\", load_document_node)\n",
    "    workflow.add_node(\"extract_facts\", extract_facts_node)\n",
    "    workflow.add_node(\"generate_verse\", generate_verse_node)\n",
    "    workflow.add_node(\"judge_poems\", judge_poems_node)\n",
    "    \n",
    "    # Define edges\n",
    "    workflow.set_entry_point(\"load_document\")\n",
    "    workflow.add_edge(\"load_document\", \"extract_facts\")\n",
    "    workflow.add_edge(\"extract_facts\", \"generate_verse\")\n",
    "    \n",
    "    # Conditional edge\n",
    "    workflow.add_conditional_edges(\n",
    "        \"generate_verse\",\n",
    "        check_completion_node,\n",
    "        {\n",
    "            \"generate\": \"generate_verse\",\n",
    "            \"judge\": \"judge_poems\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    workflow.add_edge(\"judge_poems\", END)\n",
    "    \n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0326164",
   "metadata": {},
   "source": [
    "### MAIN FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7e0033dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_collaborative_poem(document_path: str, num_verses: int = 8) -> Dict:\n",
    "    \"\"\"Main function to generate collaborative poem\"\"\"\n",
    "    \n",
    "    # Create workflow\n",
    "    app = create_poetry_workflow()\n",
    "    \n",
    "    # Initial state\n",
    "    initial_state = {\n",
    "        \"document_path\": document_path,\n",
    "        \"document_text\": \"\",\n",
    "        \"factual_context\": {},\n",
    "        \"verses\": [],\n",
    "        \"current_verse_num\": 1,\n",
    "        \"max_verses\": num_verses,\n",
    "        \"poet_turn\": \"poet_a\",\n",
    "        \"judgments\": [],\n",
    "        \"winner\": \"\",\n",
    "        \"error\": \"\"\n",
    "    }\n",
    "    \n",
    "    # Run workflow\n",
    "    final_state = app.invoke(initial_state)\n",
    "    \n",
    "    return {\n",
    "        'document_path': document_path,\n",
    "        'factual_context': final_state['factual_context'],\n",
    "        'verses': final_state['verses'],\n",
    "        'judgments': final_state['judgments'],\n",
    "        'winner': final_state['winner']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "db1b4f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df200d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emon1\\Desktop\\2.0\\task\\sample_document.txt\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e91b9c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting collaborative poetry generation...\n",
      "================================================================================\n",
      "   Entities: 7\n",
      "   Key Facts: 5\n",
      "   Themes: 5\n",
      "  Verse 1: Poet A (Metaphorical)\n",
      "   \"July 20, 1969, Armstrong and Aldrin kissed the Moon's silver...\"\n",
      "  Verse 2: Poet B (Narrative)\n",
      "   \"On July 16, 1969, Saturn V roared from Kennedy Space Center,...\"\n",
      "  Verse 3: Poet A (Metaphorical)\n",
      "   \"For 21.5 hours they gathered 47.5 pounds of moon‑dust, while...\"\n",
      "  Verse 4: Poet B (Narrative)\n",
      "   \"Armstrong’s words, “one small step…,” echoed worldwide as Ea...\"\n",
      "  Verse 5: Poet A (Metaphorical)\n",
      "   \"Armstrong and Aldrin’s boots pressed moon‑kissed seas, turni...\"\n",
      "  Verse 6: Poet B (Narrative)\n",
      "   \"After 21.5 hours, Armstrong and Aldrin lifted off, returning...\"\n",
      "  Verse 7: Poet A (Metaphorical)\n",
      "   \"Armstrong and Aldrin's shadows stretched like comet tails, t...\"\n",
      "  Verse 8: Poet B (Narrative)\n",
      "   \"Neil Armstrong and Buzz Aldrin docked, ending 21.5 hours on ...\"\n",
      "Judging contributions...\n",
      "   Evaluating Poet A (Metaphorical)...\n",
      "   Evaluating Poet B (Narrative)...\n",
      "\n",
      "================================================================================\n",
      "                               COLLABORATIVE POEM                               \n",
      "================================================================================\n",
      "\n",
      "1. [Poet A (Metaphorical)]\n",
      "   July 20, 1969, Armstrong and Aldrin kissed the Moon's silver dunes, a quiet sunrise for humanity.\n",
      "   Facts: Neil Armstrong, Buzz Aldrin, July 20 1969\n",
      "\n",
      "2. [Poet B (Narrative)]\n",
      "   On July 16, 1969, Saturn V roared from Kennedy Space Center, launching Apollo 11 toward destiny.\n",
      "   Facts: July 16 1969, Kennedy Space Center, Apollo 11 mission\n",
      "\n",
      "3. [Poet A (Metaphorical)]\n",
      "   For 21.5 hours they gathered 47.5 pounds of moon‑dust, while 600 million Earth‑hearts beat as one.\n",
      "   Facts: Neil Armstrong, Buzz Aldrin, 21.5 hours\n",
      "\n",
      "4. [Poet B (Narrative)]\n",
      "   Armstrong’s words, “one small step…,” echoed worldwide as Earth’s 600 million listeners cheered the historic stride.\n",
      "   Facts: Neil Armstrong, “That's one small step for man, one giant leap for mankind”\n",
      "\n",
      "5. [Poet A (Metaphorical)]\n",
      "   Armstrong and Aldrin’s boots pressed moon‑kissed seas, turning 47.5 pounds of stardust into Earth’s whispered promise.\n",
      "   Facts: Neil Armstrong, Buzz Aldrin, 47.5 pounds of lunar material\n",
      "\n",
      "6. [Poet B (Narrative)]\n",
      "   After 21.5 hours, Armstrong and Aldrin lifted off, returning the 47.5 pounds of lunar treasure to Earth.\n",
      "   Facts: 21.5 hours, 47.5 pounds, Neil Armstrong\n",
      "\n",
      "7. [Poet A (Metaphorical)]\n",
      "   Armstrong and Aldrin's shadows stretched like comet tails, tracing July 20, 1969 across the Moon's quiet seas.\n",
      "   Facts: Neil Armstrong, Buzz Aldrin, July 20 1969\n",
      "\n",
      "8. [Poet B (Narrative)]\n",
      "   Neil Armstrong and Buzz Aldrin docked, ending 21.5 hours on the Moon and heading home.\n",
      "   Facts: Neil Armstrong, Buzz Aldrin, 21.5 hours\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                                   JUDGMENTS                                    \n",
      "================================================================================\n",
      "\n",
      "\n",
      "Poet A (Metaphorical)\n",
      "----------------------------------------\n",
      "Overall Score: 8.05/10\n",
      "\n",
      "Detailed Scores:\n",
      "  Factual Accuracy: 9.0/10\n",
      "  Poetic Quality: 8.0/10\n",
      "  Coherence: 7.0/10\n",
      "  Creativity: 8.0/10\n",
      "  Emotional Impact: 8.0/10\n",
      "\n",
      "Strengths:\n",
      "  Vivid, sensory imagery (“kissed the Moon's silver dunes,” “shadows stretched like comet tails”) that paints a memorable picture of the landing.\n",
      "  Skillful integration of hard data (July 20 1969, 21.5 hours, 47.5 pounds, 600 million) into metaphor, turning numbers into emotional beats.\n",
      "  Consistent tone that reinforces the poem’s overarching contrast between factual narrative and lyrical reflection.\n",
      "\n",
      "Weaknesses:\n",
      "  A few mixed metaphors (“moon‑kissed seas,” “stardust into Earth’s whispered promise”) can momentarily blur the visual focus.\n",
      "  Slight factual stretch in line 3 (“gathered 47.5 pounds of moon‑dust” suggests continuous collection for the whole 21.5 hours, whereas the astronauts collected that amount overall.\n",
      "\n",
      "Standout Verses: 1, 3, 7\n",
      "\n",
      "Reasoning:\n",
      "Poet A’s verses are firmly anchored in the source material, correctly citing the date, duration, mass of lunar material, and the global audience of 600 million. The only minor slip is the implication that the dust was “gathered” continuously for the entire 21.5 hours, which is a small factual nuance...\n",
      "\n",
      "Poet B (Narrative)\n",
      "----------------------------------------\n",
      "Overall Score: 5.00/10\n",
      "\n",
      "Detailed Scores:\n",
      "  Factual Accuracy: 5.0/10\n",
      "  Poetic Quality: 5.0/10\n",
      "  Coherence: 5.0/10\n",
      "  Creativity: 5.0/10\n",
      "  Emotional Impact: 5.0/10\n",
      "\n",
      "Strengths:\n",
      "  Evaluation completed\n",
      "\n",
      "Weaknesses:\n",
      "  See detailed feedback\n",
      "\n",
      "Reasoning:\n",
      "Detailed analysis provided above....\n",
      "\n",
      "================================================================================\n",
      "WINNER: Poet A (Metaphorical)\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Example usage\"\"\"\n",
    "    \n",
    "    # Check for API key\n",
    "    api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "    document_path = Path(\"sample_document.txt\").resolve()\n",
    "    \n",
    "    if not os.path.exists(document_path):\n",
    "        sample_text = \"\"\"The Moon landing occurred on July 20, 1969, when Neil Armstrong \n",
    "        and Buzz Aldrin became the first humans to walk on the lunar surface. The Apollo 11 \n",
    "        mission launched from Kennedy Space Center on July 16, 1969. Armstrong's famous words \n",
    "        \"That's one small step for man, one giant leap for mankind\" were broadcast to an \n",
    "        estimated 600 million people watching on Earth. The astronauts spent 21.5 hours on \n",
    "        the Moon's surface and collected 47.5 pounds of lunar material.\"\"\"\n",
    "        \n",
    "        with open(document_path, 'w') as f:\n",
    "            f.write(sample_text)\n",
    "        print(f\"Created sample document: {document_path}\")\n",
    "        \n",
    "    \n",
    "    # Generate poem\n",
    "    print(\"\\nStarting collaborative poetry generation...\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    results = generate_collaborative_poem(document_path, num_verses=8)\n",
    "    \n",
    "    # Display results\n",
    "    display_results(results)\n",
    "    \n",
    "    # Convert Path to string for JSON\n",
    "    results['document_path'] = str(results['document_path'])\n",
    "\n",
    "    # Save results\n",
    "    output_file = 'poem_results.json'\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    # # Save results\n",
    "    # output_file = 'poem_results.json'\n",
    "    # with open(output_file, 'w') as f:\n",
    "    #     json.dump(results, f, indent=2)\n",
    "    # print(f\"\\nResults saved to {output_file}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
